
# ğŸ¤– Human Action Recognition System

![Python](https://img.shields.io/badge/Language-Python-blue?logo=python)
![Keras](https://img.shields.io/badge/Framework-Keras-orange?logo=keras)
![Tensorflow](https://img.shields.io/badge/Library-TensorFlow-yellow?logo=tensorflow)
![Semester Project](https://img.shields.io/badge/SE%20Semester%20Project-informational)

---

## ğŸ“Œ Overview

**Human Action Recognition System** is an AI-powered deep learning project that identifies and classifies human activities from image and video data. Developed as a Software Engineering semester project at **Bahria University Islamabad Campus**, the system uses a convolutional neural network (CNN) architecture based on MobileNetV2, offering real-time action recognition through an intuitive PyQt-based interface.

---

## ğŸ¯ Objectives

- Recognize 15 predefined human actions using computer vision and deep learning.
- Provide a **user-friendly GUI** for image/video input and real-time prediction.
- Ensure compatibility with PC and smartphone cameras.
- Support exporting results for further analysis.

---

## âš™ï¸ Features

- ğŸ“· **Real-Time Detection** from live video streams
- ğŸ–¼ï¸ **Image and Video Upload Support**
- ğŸ§  **Deep Learning with MobileNetV2**
- ğŸ“Š **Action Visualization** with performance stats
- ğŸ“ **Result Exporting** (planned CSV/JSON support)
- ğŸ–¥ï¸ **Clean GUI Interface** using PyQt5
- ğŸ”„ **Integrated Data Augmentation Pipeline**

---

## ğŸ§ª Supported Action Classes

1. Running
2. Sitting
3. Fighting
4. Dancing
5. Calling
6. Clapping
7. Cycling
8. Drinking
9. Eating
10. Hugging
11. Laughing
12. Listening to Music
13. Sleeping
14. Texting
15. Using Laptop

---

## ğŸ—‚ï¸ Repository Structure

```

Human-Action-Recognition-System/
â”œâ”€â”€ Activity Diagram.png              # Activity workflow visualization
â”œâ”€â”€ Architecture Diagram.jpg          # System architecture overview
â”œâ”€â”€ Class Diagram.png                 # Class relationships and structure
â”œâ”€â”€ Front End.jpg                     # Frontend UI screenshot
â”œâ”€â”€ Sequence Diagram.png              # Sequence of system interactions
â”œâ”€â”€ human_action_model_improved.h5   # Trained AI model
â”œâ”€â”€ Report.pdf                        # Final report document
â”œâ”€â”€ README.md                         # Project documentation
â”œâ”€â”€ train.py                          # Model training script
â”œâ”€â”€ test.py                           # Model evaluation script
â”œâ”€â”€ test_gui.py                       # GUI interaction testing script


````

---

## ğŸ“Š System Diagrams

### ğŸ” Activity Diagram
<img src="Activity Diagram.png" alt="Activity Diagram" width="600"/>

### ğŸ“ Architecture Diagram
<img src="Architecture Diagram.jpg" alt="Architecture Diagram" width="600"/>

### ğŸ§© Class Diagram
<img src="Class Diagram.png" alt="Class Diagram" width="600"/>

### ğŸ§­ Sequence Diagram
<img src="Sequence Diagram.png" alt="Sequence Diagram" width="600"/>

### ğŸ–¥ï¸ Front-End UI Design
<img src="Front End.jpg" alt="Front End UI" width="600"/>



---

## ğŸ§  Technologies Used

| Technology       | Purpose                          |
|------------------|----------------------------------|
| **Python**       | Backend development              |
| **Keras / TensorFlow** | Deep learning model architecture |
| **OpenCV**       | Image/video frame handling       |
| **NumPy**        | Data processing                  |
| **PyQt5**        | Desktop GUI development          |

---

## ğŸ”§ Dataset Details

- **Name:** Human Action Recognition Dataset
- **Source:** Kaggle (by Shashank Rapolu)
- **Total Images:** 12,600 (Train: 10,710 | Test: 1,890)
- **Classes:** 15 human actions (listed above)
- **Formats:** `.jpg` images in class-wise directories
- **Augmentation:** Flip, zoom, brightness, rotation, etc.

---

## ğŸ“¦ Installation & Usage

### ğŸ“¥ Dependencies

Install via pip:

```bash
pip install -r requirements.txt
````

### ğŸš€ Running the System

```bash
python main.py
```

* Click `Upload` to load image/video
* Click `Detect` to identify the action
* View results in the GUI and visual preview

---

## ğŸ“¢ Project Showcase

ğŸš€ See live demo and project walkthrough on our LinkedIn:
[ğŸ”— LinkedIn Showcase](https://shorturl.at/qhb75)

---

## ğŸ“œ License

This project is submitted for academic evaluation only under **Bahria University, Islamabad**'s **SE Semester Project** requirements.

---

## ğŸ™Œ Acknowledgments

**Instructor:** Ms. Sara Durrani

**Team Members:**

* Muhammad Awab Sial
* Syed Amber Ali Shah
* Fawad Naveed

